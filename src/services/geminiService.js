const GEMINI_API_KEY = 'AIzaSyAf-Oe56q4Rao0OodEOtnEjtI_FpOmDg6I';

// Lista de modelos em ordem de prioridade (do mais novo e r√°pido para o mais antigo)
const GEMINI_MODELS = [
  {
    name: 'gemini-2.0-flash-exp',
    url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
    description: 'Gemini 2.0 Flash (Mais Novo e R√°pido - Experimental)'
  },
  {
    name: 'gemini-1.5-flash',
    url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent',
    description: 'Gemini 1.5 Flash (R√°pido e Eficiente)'
  },
  {
    name: 'gemini-1.5-pro',
    url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent',
    description: 'Gemini 1.5 Pro (Mais Avan√ßado)'
  },
  {
    name: 'gemini-1.0-pro',
    url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.0-pro:generateContent',
    description: 'Gemini 1.0 Pro (Vers√£o Est√°vel)'
  }
];

// Configura√ß√µes de retry por modelo (mais agressivo para o 2.0 Flash)
const RETRY_CONFIG = {
  maxRetries: 3, // Reduzido para ser mais r√°pido
  baseDelay: 800, // Delay inicial menor
  maxDelay: 12000, // Delay m√°ximo menor
  backoffFactor: 1.8 // Fator de crescimento menor
};

// Fun√ß√£o para aguardar um tempo espec√≠fico
const sleep = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// Fun√ß√£o para calcular o delay com exponential backoff
const calculateDelay = (attempt) => {
  const delay = RETRY_CONFIG.baseDelay * Math.pow(RETRY_CONFIG.backoffFactor, attempt);
  return Math.min(delay, RETRY_CONFIG.maxDelay);
};

// Fun√ß√£o para verificar se o erro √© tempor√°rio e deve ser retentado
const isRetryableError = (error, response) => {
  // Erros de rede
  if (error && error.message && error.message.includes('Failed to fetch')) {
    return true;
  }
  
  // Erros HTTP tempor√°rios
  if (response) {
    const status = response.status;
    // 429 (Too Many Requests), 503 (Service Unavailable), 502 (Bad Gateway), 504 (Gateway Timeout)
    return status === 429 || status === 503 || status === 502 || status === 504;
  }
  
  return false;
};

// Fun√ß√£o para verificar se deve tentar outro modelo
const shouldTryNextModel = (error, response) => {
  // Se √© um erro tempor√°rio, continuar tentando o mesmo modelo
  if (isRetryableError(error, response)) {
    return false;
  }
  
  // Se √© um erro permanente, tentar pr√≥ximo modelo
  if (response) {
    const status = response.status;
    // 400 (Bad Request), 401 (Unauthorized), 403 (Forbidden), 404 (Not Found), 500 (Internal Server Error)
    return status === 400 || status === 401 || status === 403 || status === 404 || status === 500;
  }
  
  return true;
};

// Fun√ß√£o para fazer parse seguro do JSON
const safeJsonParse = (text) => {
  try {
    return JSON.parse(text);
  } catch (e) {
    console.error('Erro ao fazer parse do JSON:', e);
    console.error('Texto que causou erro:', text);
    return null;
  }
};

// Fun√ß√£o para tentar um modelo espec√≠fico
const tryModel = async (model, message, attempt = 0) => {
  try {
    const apiUrl = `${model.url}?key=${GEMINI_API_KEY}`;

    console.log(`Tentando modelo ${model.name} (tentativa ${attempt + 1}/${RETRY_CONFIG.maxRetries + 1})`);

    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: `Voc√™ √© o QualiBot 2.0, um assistente especializado em licita√ß√µes e compras p√∫blicas, com foco em ajudar os usu√°rios de forma r√°pida e eficiente. Responda a seguinte pergunta de forma clara e objetiva, usando sua expertise em licita√ß√µes: ${message}`
          }]
        }]
      })
    });

    console.log(`Resposta do modelo ${model.name}:`, {
      status: response.status,
      statusText: response.statusText,
      ok: response.ok
    });

    const responseText = await response.text();
    
    // Se a resposta n√£o for OK, verificar tipo de erro
    if (!response.ok) {
      const isTemporaryError = isRetryableError(null, response);
      
      if (isTemporaryError && attempt < RETRY_CONFIG.maxRetries) {
        const delay = calculateDelay(attempt);
        console.log(`Erro tempor√°rio (${response.status}) no modelo ${model.name}. Aguardando ${delay}ms...`);
        await sleep(delay);
        return tryModel(model, message, attempt + 1);
      }
      
      // Erro permanente ou esgotaram tentativas
      let errorData = safeJsonParse(responseText);
      if (!errorData) {
        errorData = { 
          error: { 
            message: `Erro HTTP ${response.status}: ${response.statusText || 'Erro desconhecido'}` 
          } 
        };
      }
      
      console.error(`Erro no modelo ${model.name}:`, errorData);
      
      // Mensagem de erro mais espec√≠fica
      let errorMessage = `Modelo ${model.name} falhou`;
      if (errorData.error && errorData.error.message) {
        errorMessage += `: ${errorData.error.message}`;
      } else {
        errorMessage += `: ${response.status} ${response.statusText || 'Erro desconhecido'}`;
      }
      
      throw new Error(errorMessage);
    }

    // Parse da resposta bem-sucedida
    const data = safeJsonParse(responseText);
    if (!data) {
      if (attempt < RETRY_CONFIG.maxRetries) {
        const delay = calculateDelay(attempt);
        console.log(`Erro de parse no modelo ${model.name}. Aguardando ${delay}ms...`);
        await sleep(delay);
        return tryModel(model, message, attempt + 1);
      }
      
      throw new Error(`Modelo ${model.name} retornou resposta inv√°lida`);
    }

    // Verificar se a resposta tem o formato esperado
    if (!data.candidates || !data.candidates[0]?.content?.parts?.[0]?.text) {
      console.error(`Formato inv√°lido no modelo ${model.name}:`, data);
      
      if (attempt < RETRY_CONFIG.maxRetries) {
        const delay = calculateDelay(attempt);
        console.log(`Formato inv√°lido no modelo ${model.name}. Aguardando ${delay}ms...`);
        await sleep(delay);
        return tryModel(model, message, attempt + 1);
      }
      
      throw new Error(`Modelo ${model.name} retornou formato inv√°lido`);
    }

    // Sucesso!
    console.log(`‚úÖ Sucesso com modelo ${model.name}!`);
    return {
      text: data.candidates[0].content.parts[0].text,
      modelUsed: model.name
    };

  } catch (error) {
    console.error(`Erro na tentativa ${attempt + 1} do modelo ${model.name}:`, error);

    // Se √© um erro de rede ou tempor√°rio e ainda h√° tentativas restantes
    if (isRetryableError(error, null) && attempt < RETRY_CONFIG.maxRetries) {
      const delay = calculateDelay(attempt);
      console.log(`Erro de rede no modelo ${model.name}. Aguardando ${delay}ms...`);
      await sleep(delay);
      return tryModel(model, message, attempt + 1);
    }

    // Re-throw o erro para ser tratado no n√≠vel superior
    throw error;
  }
};

export const geminiService = {
  async chat(message) {
    let lastError = null;
    let modelsAttempted = [];
    
    // Tentar cada modelo em ordem de prioridade
    for (let i = 0; i < GEMINI_MODELS.length; i++) {
      const model = GEMINI_MODELS[i];
      modelsAttempted.push(model.name);
      
      try {
        console.log(`üöÄ Tentando modelo ${i + 1}/${GEMINI_MODELS.length}: ${model.name}`);
        const result = await tryModel(model, message);
        
        // Adicionar informa√ß√£o sobre qual modelo foi usado (apenas no console)
        console.log(`‚úÖ Resposta obtida com sucesso usando: ${result.modelUsed}`);
        
        return result.text;
        
      } catch (error) {
        lastError = error;
        console.error(`‚ùå Modelo ${model.name} falhou:`, error.message);
        
        // Se n√£o √© o √∫ltimo modelo, tentar o pr√≥ximo
        if (i < GEMINI_MODELS.length - 1) {
          console.log(`üîÑ Tentando pr√≥ximo modelo: ${GEMINI_MODELS[i + 1].name}`);
          continue;
        }
      }
    }

    // Se chegou aqui, todos os modelos falharam
    console.error('‚ùå Todos os modelos falharam. Modelos tentados:', modelsAttempted);
    console.error('√öltimo erro:', lastError);
    
    // Retornar erro baseado no √∫ltimo erro encontrado
    if (lastError && lastError.message && lastError.message.includes('Failed to fetch')) {
      throw new Error('N√£o foi poss√≠vel conectar aos servi√ßos de IA. Verifique sua conex√£o com a internet.');
    }
    
    if (lastError && lastError.message && (lastError.message.includes('503') || lastError.message.includes('sobrecarregado'))) {
      throw new Error('Todos os servi√ßos de IA est√£o temporariamente sobrecarregados. Tente novamente em alguns minutos.');
    }
    
    if (lastError && lastError.message && lastError.message.includes('429')) {
      throw new Error('Limite de requisi√ß√µes atingido. Aguarde alguns minutos antes de tentar novamente.');
    }
    
    throw new Error('Todos os servi√ßos de IA est√£o temporariamente indispon√≠veis. Tente novamente mais tarde.');
  }
}; 